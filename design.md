
# SLMチャットアプリ
モデルの性能に頼らずに工程を最適化することで役立つアシスタントとして応答する

## 技術スタック
Python + Ollama + llama3.1:8b
SQLite

## データ構造

属性マスタ（属性ID、属性名称、抽出プロンプト、判定プロンプト）
属性テーブル（シーケンスNO、属性ID、内容、登録日、更新日）

例
属性マスタ (1, 'プロフィール', '文章の中にユーザーのプロフィールが含まれている場合、抽出してください 例: 私はエンジニアです', '次の文章に答えるにはユーザーのプロフィールが必要か答えてください 例: いいえ')

## UI

・ チャット画面
    応答の編集ステータス（LLMに何のタスクを投げているか）をリアルタイムで表示する

・ ログ確認画面
  LLMとのすべての応答（送信 /　受信）を一覧表示

・ 属性マスタ保守画面（追加・変更・削除）
・ 属性テーブル保守画面（追加・変更・削除）
    属性集計機能（同じ属性を１つにまとめる。１つ１つの属性をLLMに同じ属性として統合可能か確認して統合する。Pythonの文字列編集で行わない。データの整理をLLMに丸投げしない）
 
## LLMへのプロンプトについて
  LLMに文章を作成させるタスクと、自然言語をjsonに変換するタスクを必ず分ける（参考: JSON-Schema-compliant.md）

## ユーザーの入力から属性テーブルの抽出、応答文の作成と表示、属性の抽出と登録の流れ

1. ユーザーの入力内容から、属性マスタに登録された１つ１つが応答に必要かLLMに判定プロンプトをつかって判定させる
2. 応答に必要と判定された属性を抽出する
3. チャット履歴 ＋ ユーザーの入力 + 抽出された属性データ を元に応答文を生成させる
4. 画面にチャットの応答を表示
5. 応答の表示が完了したら、１のユーザーの入力に属性に登録する内容がないか、属性マスタ１つ１つの抽出プロンプトを使って確認と抽出、抽出できれば登録を行う
   
このLLMにタスクを投げたタイミングで画面のステータス表示欄に何をさせているか表示する

## 要望
優秀なアシスタントや秘書が、サポート対象者の情報を分類して記録する仕事を参考に、必要な属性を作成してください



